{
    "sourceFile": "app.js",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 20,
            "patches": [
                {
                    "date": 1693164066955,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1693322961382,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -38,4 +38,68 @@\n document.getElementById('playAudio').onclick = function() {\n     let lastRecording = document.getElementById('recordingsList').lastChild.firstChild;\n     lastRecording.play();\n };\n+// ... Existing JavaScript for recording ...\n+\n+document.getElementById('translate').onclick = function() {\n+    // Assuming the last recorded audio is what we want to translate\n+    let lastRecordingBlob = document.getElementById('recordingsList').lastChild.firstChild.src; // This might need adjustments depending on how you store the blob\n+    let targetLanguage = document.getElementById('languageSelect').value;\n+\n+    convertAudioToText(lastRecordingBlob)\n+        .then(text => translateText(text, targetLanguage))\n+        .then(translatedText => {\n+            document.getElementById('translatedText').innerText = translatedText;\n+        })\n+        .catch(error => {\n+            console.error(\"Error during translation:\", error);\n+        });\n+};\n+\n+function convertAudioToText(audioBlob) {\n+    let formData = new FormData();\n+    formData.append('audio', audioBlob);\n+\n+    // Use your backend endpoint for Speech-to-Text conversion\n+    return fetch('/api/convertAudioToText', {\n+        method: 'POST',\n+        body: formData\n+    })\n+    .then(response => response.json())\n+    .then(data => data.text);\n+}\n+\n+function translateText(text, targetLanguage) {\n+    // Use your backend endpoint for translation\n+    return fetch('/api/translateText', {\n+        method: 'POST',\n+        body: JSON.stringify({ text: text, targetLanguage: targetLanguage }),\n+        headers: {\n+            'Content-Type': 'application/json'\n+        }\n+    })\n+    .then(response => response.json())\n+    .then(data => data.translatedText);\n+}\n+\n+// Fetch available languages dynamically from your backend\n+fetchAvailableLanguages()\n+    .then(languages => {\n+        let select = document.getElementById('languageSelect');\n+        languages.forEach(lang => {\n+            let option = document.createElement('option');\n+            option.value = lang.code;\n+            option.innerText = lang.name;\n+            select.appendChild(option);\n+        });\n+    })\n+    .catch(error => {\n+        console.error(\"Error fetching languages:\", error);\n+    });\n+\n+function fetchAvailableLanguages() {\n+    // Use your backend endpoint for fetching available languages\n+    return fetch('/api/availableLanguages')\n+    .then(response => response.json())\n+    .then(data => data.languages);\n+}\n"
                },
                {
                    "date": 1693323218977,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -17,16 +17,20 @@\n                 let li = document.createElement('li');\n                 let audio = new Audio(url);\n                 audio.controls = true;\n                 li.appendChild(audio);\n+                li.dataset.blob = blob; // Store the blob in a dataset for later use\n                 document.getElementById('recordingsList').appendChild(li);\n                 document.getElementById('playAudio').disabled = false;\n                 recordedChunks = [];\n             };\n \n             mediaRecorder.start();\n             document.getElementById('startRecord').disabled = true;\n             document.getElementById('stopRecord').disabled = false;\n+        })\n+        .catch(error => {\n+            console.error(\"Error accessing the microphone:\", error);\n         });\n };\n \n document.getElementById('stopRecord').onclick = function() {\n@@ -36,15 +40,16 @@\n };\n \n document.getElementById('playAudio').onclick = function() {\n     let lastRecording = document.getElementById('recordingsList').lastChild.firstChild;\n-    lastRecording.play();\n+    if (lastRecording && lastRecording.play) {\n+        lastRecording.play();\n+    }\n };\n-// ... Existing JavaScript for recording ...\n \n document.getElementById('translate').onclick = function() {\n-    // Assuming the last recorded audio is what we want to translate\n-    let lastRecordingBlob = document.getElementById('recordingsList').lastChild.firstChild.src; // This might need adjustments depending on how you store the blob\n+    // Retrieve the last recorded audio blob\n+    let lastRecordingBlob = document.getElementById('recordingsList').lastChild.dataset.blob;\n     let targetLanguage = document.getElementById('languageSelect').value;\n \n     convertAudioToText(lastRecordingBlob)\n         .then(text => translateText(text, targetLanguage))\n"
                },
                {
                    "date": 1693323558066,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,6 +1,7 @@\n let mediaRecorder;\n let recordedChunks = [];\n+let recordedBlobs = []; // New array to store audio blobs\n \n document.getElementById('startRecord').onclick = function() {\n     navigator.mediaDevices.getUserMedia({ audio: true })\n         .then(stream => {\n@@ -17,9 +18,10 @@\n                 let li = document.createElement('li');\n                 let audio = new Audio(url);\n                 audio.controls = true;\n                 li.appendChild(audio);\n-                li.dataset.blob = blob; // Store the blob in a dataset for later use\n+                li.dataset.blobIndex = recordedBlobs.length; // Store the index of the blob in the dataset\n+                recordedBlobs.push(blob); // Store the blob in the global array\n                 document.getElementById('recordingsList').appendChild(li);\n                 document.getElementById('playAudio').disabled = false;\n                 recordedChunks = [];\n             };\n@@ -47,9 +49,10 @@\n };\n \n document.getElementById('translate').onclick = function() {\n     // Retrieve the last recorded audio blob\n-    let lastRecordingBlob = document.getElementById('recordingsList').lastChild.dataset.blob;\n+    let blobIndex = document.getElementById('recordingsList').lastChild.dataset.blobIndex;\n+    let lastRecordingBlob = recordedBlobs[blobIndex];\n     let targetLanguage = document.getElementById('languageSelect').value;\n \n     convertAudioToText(lastRecordingBlob)\n         .then(text => translateText(text, targetLanguage))\n@@ -73,38 +76,5 @@\n     .then(response => response.json())\n     .then(data => data.text);\n }\n \n-function translateText(text, targetLanguage) {\n-    // Use your backend endpoint for translation\n-    return fetch('/api/translateText', {\n-        method: 'POST',\n-        body: JSON.stringify({ text: text, targetLanguage: targetLanguage }),\n-        headers: {\n-            'Content-Type': 'application/json'\n-        }\n-    })\n-    .then(response => response.json())\n-    .then(data => data.translatedText);\n-}\n-\n-// Fetch available languages dynamically from your backend\n-fetchAvailableLanguages()\n-    .then(languages => {\n-        let select = document.getElementById('languageSelect');\n-        languages.forEach(lang => {\n-            let option = document.createElement('option');\n-            option.value = lang.code;\n-            option.innerText = lang.name;\n-            select.appendChild(option);\n-        });\n-    })\n-    .catch(error => {\n-        console.error(\"Error fetching languages:\", error);\n-    });\n-\n-function fetchAvailableLanguages() {\n-    // Use your backend endpoint for fetching available languages\n-    return fetch('/api/availableLanguages')\n-    .then(response => response.json())\n-    .then(data => data.languages);\n-}\n+// ... rest of the code remains unchanged ...\n"
                },
                {
                    "date": 1693325537909,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,80 +1,62 @@\n let mediaRecorder;\n-let recordedChunks = [];\n-let recordedBlobs = []; // New array to store audio blobs\n+let audioChunks = [];\n+let audioBlob;\n+let audioUrl;\n+let audio = new Audio();\n \n-document.getElementById('startRecord').onclick = function() {\n-    navigator.mediaDevices.getUserMedia({ audio: true })\n-        .then(stream => {\n-            mediaRecorder = new MediaRecorder(stream);\n-            mediaRecorder.ondataavailable = function(event) {\n-                if (event.data.size > 0) {\n-                    recordedChunks.push(event.data);\n-                }\n-            };\n-            \n-            mediaRecorder.onstop = function() {\n-                let blob = new Blob(recordedChunks, { type: 'audio/wav' });\n-                let url = URL.createObjectURL(blob);\n-                let li = document.createElement('li');\n-                let audio = new Audio(url);\n-                audio.controls = true;\n-                li.appendChild(audio);\n-                li.dataset.blobIndex = recordedBlobs.length; // Store the index of the blob in the dataset\n-                recordedBlobs.push(blob); // Store the blob in the global array\n-                document.getElementById('recordingsList').appendChild(li);\n-                document.getElementById('playAudio').disabled = false;\n-                recordedChunks = [];\n-            };\n+document.getElementById(\"startRecord\").addEventListener(\"click\", startRecording);\n+document.getElementById(\"stopRecord\").addEventListener(\"click\", stopRecording);\n+document.getElementById(\"playAudio\").addEventListener(\"click\", playLastRecording);\n+document.getElementById(\"translate\").addEventListener(\"click\", translateRecording);\n \n-            mediaRecorder.start();\n-            document.getElementById('startRecord').disabled = true;\n-            document.getElementById('stopRecord').disabled = false;\n-        })\n-        .catch(error => {\n-            console.error(\"Error accessing the microphone:\", error);\n-        });\n-};\n+async function startRecording() {\n+    let stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n+    mediaRecorder = new MediaRecorder(stream);\n+    mediaRecorder.ondataavailable = event => {\n+        audioChunks.push(event.data);\n+    };\n+    mediaRecorder.onstop = () => {\n+        audioBlob = new Blob(audioChunks, { type: 'audio/wav' });\n+        audioUrl = URL.createObjectURL(audioBlob);\n+        audio.src = audioUrl;\n+    };\n+    audioChunks = [];\n+    mediaRecorder.start();\n+    document.getElementById(\"startRecord\").disabled = true;\n+    document.getElementById(\"stopRecord\").disabled = false;\n+}\n \n-document.getElementById('stopRecord').onclick = function() {\n+function stopRecording() {\n     mediaRecorder.stop();\n-    document.getElementById('startRecord').disabled = false;\n-    document.getElementById('stopRecord').disabled = true;\n-};\n+    document.getElementById(\"startRecord\").disabled = false;\n+    document.getElementById(\"stopRecord\").disabled = true;\n+    document.getElementById(\"playAudio\").disabled = false;\n+}\n \n-document.getElementById('playAudio').onclick = function() {\n-    let lastRecording = document.getElementById('recordingsList').lastChild.firstChild;\n-    if (lastRecording && lastRecording.play) {\n-        lastRecording.play();\n+function playLastRecording() {\n+    audio.play();\n+}\n+\n+function translateRecording() {\n+    if(!audioBlob) {\n+        alert(\"Please record something first!\");\n+        return;\n     }\n-};\n-\n-document.getElementById('translate').onclick = function() {\n-    // Retrieve the last recorded audio blob\n-    let blobIndex = document.getElementById('recordingsList').lastChild.dataset.blobIndex;\n-    let lastRecordingBlob = recordedBlobs[blobIndex];\n-    let targetLanguage = document.getElementById('languageSelect').value;\n-\n-    convertAudioToText(lastRecordingBlob)\n-        .then(text => translateText(text, targetLanguage))\n-        .then(translatedText => {\n-            document.getElementById('translatedText').innerText = translatedText;\n-        })\n-        .catch(error => {\n-            console.error(\"Error during translation:\", error);\n-        });\n-};\n-\n-function convertAudioToText(audioBlob) {\n-    let formData = new FormData();\n-    formData.append('audio', audioBlob);\n-\n-    // Use your backend endpoint for Speech-to-Text conversion\n-    return fetch('/api/convertAudioToText', {\n-        method: 'POST',\n-        body: formData\n-    })\n-    .then(response => response.json())\n-    .then(data => data.text);\n+    // Placeholder for sending the audioBlob to a voice-to-text service\n+    let transcribedText = \"This is a placeholder for the transcribed text.\";\n+    \n+    // Placeholder for sending the transcribedText to a translation API\n+    let translatedText = \"This is a placeholder for the translated text.\";\n+    \n+    document.getElementById(\"translatedText\").innerText = translatedText;\n }\n \n-// ... rest of the code remains unchanged ...\n+// Placeholder for fetching the list of languages from an API\n+let languages = [\"English\", \"Spanish\", \"French\"]; // example languages\n+let languageSelect = document.getElementById(\"languageSelect\");\n+languages.forEach(lang => {\n+    let option = document.createElement(\"option\");\n+    option.value = lang;\n+    option.innerText = lang;\n+    languageSelect.appendChild(option);\n+});\n"
                },
                {
                    "date": 1693328393654,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,8 +2,9 @@\n let audioChunks = [];\n let audioBlob;\n let audioUrl;\n let audio = new Audio();\n+let recordingInterval;\n \n document.getElementById(\"startRecord\").addEventListener(\"click\", startRecording);\n document.getElementById(\"stopRecord\").addEventListener(\"click\", stopRecording);\n document.getElementById(\"playAudio\").addEventListener(\"click\", playLastRecording);\n@@ -18,24 +19,41 @@\n     mediaRecorder.onstop = () => {\n         audioBlob = new Blob(audioChunks, { type: 'audio/wav' });\n         audioUrl = URL.createObjectURL(audioBlob);\n         audio.src = audioUrl;\n+        const audioPlayer = document.getElementById(\"audioPlayer\");\n+        audioPlayer.src = audioUrl;\n+        audioPlayer.style.display = \"block\";\n     };\n     audioChunks = [];\n     mediaRecorder.start();\n     document.getElementById(\"startRecord\").disabled = true;\n     document.getElementById(\"stopRecord\").disabled = false;\n+\n+    let recordingDuration = 0;\n+    document.getElementById(\"recordingStatus\").textContent = \"Recording: 00:00\";\n+    recordingInterval = setInterval(() => {\n+        recordingDuration += 1;\n+        let minutes = Math.floor(recordingDuration / 60);\n+        let seconds = recordingDuration % 60;\n+        document.getElementById(\"recordingStatus\").textContent = `Recording: ${String(minutes).padStart(2, '0')}:${String(seconds).padStart(2, '0')}`;\n+    }, 1000);\n }\n \n function stopRecording() {\n     mediaRecorder.stop();\n     document.getElementById(\"startRecord\").disabled = false;\n     document.getElementById(\"stopRecord\").disabled = true;\n     document.getElementById(\"playAudio\").disabled = false;\n+\n+    clearInterval(recordingInterval);\n+    document.getElementById(\"recordingStatus\").textContent = \"Recording Stopped\";\n }\n \n function playLastRecording() {\n-    audio.play();\n+    const audioPlayer = document.getElementById(\"audioPlayer\");\n+    audioPlayer.currentTime = 0;\n+    audioPlayer.play();\n }\n \n function translateRecording() {\n     if(!audioBlob) {\n"
                },
                {
                    "date": 1693331950806,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -19,11 +19,16 @@\n     mediaRecorder.onstop = () => {\n         audioBlob = new Blob(audioChunks, { type: 'audio/wav' });\n         audioUrl = URL.createObjectURL(audioBlob);\n         audio.src = audioUrl;\n+        \n         const audioPlayer = document.getElementById(\"audioPlayer\");\n         audioPlayer.src = audioUrl;\n         audioPlayer.style.display = \"block\";\n+\n+        const downloadLink = document.getElementById(\"downloadAudio\");\n+        downloadLink.href = audioUrl;\n+        downloadLink.style.display = \"block\";\n     };\n     audioChunks = [];\n     mediaRecorder.start();\n     document.getElementById(\"startRecord\").disabled = true;\n@@ -54,27 +59,17 @@\n     audioPlayer.currentTime = 0;\n     audioPlayer.play();\n }\n \n-function translateRecording() {\n-    if(!audioBlob) {\n+async function translateRecording() {\n+    if (!audioBlob) {\n         alert(\"Please record something first!\");\n         return;\n     }\n     // Placeholder for sending the audioBlob to a voice-to-text service\n-    let transcribedText = \"This is a placeholder for the transcribed text.\";\n+    let transcribedText = \"This is a placeholder for the transcribed text.\"; // This should be replaced with actual transcribed text\n     \n-    // Placeholder for sending the transcribedText to a translation API\n-    let translatedText = \"This is a placeholder for the translated text.\";\n+    const sourceLang = 'en'; // Assuming the source language is English\n+    const targetLang = document.getElementById(\"languageSelect\").value;\n     \n-    document.getElementById(\"translatedText\").innerText = translatedText;\n+    await translateText(sourceLang, targetLang, transcribedText);\n }\n-\n-// Placeholder for fetching the list of languages from an API\n-let languages = [\"English\", \"Spanish\", \"French\"]; // example languages\n-let languageSelect = document.getElementById(\"languageSelect\");\n-languages.forEach(lang => {\n-    let option = document.createElement(\"option\");\n-    option.value = lang;\n-    option.innerText = lang;\n-    languageSelect.appendChild(option);\n-});\n"
                },
                {
                    "date": 1693332328002,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,4 +72,6 @@\n     const targetLang = document.getElementById(\"languageSelect\").value;\n     \n     await translateText(sourceLang, targetLang, transcribedText);\n }\n+// Populate the language dropdown on page load\n+populateLanguageDropdown();\n"
                },
                {
                    "date": 1693334180554,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,8 +10,12 @@\n document.getElementById(\"playAudio\").addEventListener(\"click\", playLastRecording);\n document.getElementById(\"translate\").addEventListener(\"click\", translateRecording);\n \n async function startRecording() {\n+    audioChunks = []; // Clear previous recording chunks\n+    audioBlob = null; // Reset previous audio blob\n+    audioUrl = null; // Reset previous audio URL\n+\n     let stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n     mediaRecorder = new MediaRecorder(stream);\n     mediaRecorder.ondataavailable = event => {\n         audioChunks.push(event.data);\n@@ -28,9 +32,8 @@\n         const downloadLink = document.getElementById(\"downloadAudio\");\n         downloadLink.href = audioUrl;\n         downloadLink.style.display = \"block\";\n     };\n-    audioChunks = [];\n     mediaRecorder.start();\n     document.getElementById(\"startRecord\").disabled = true;\n     document.getElementById(\"stopRecord\").disabled = false;\n \n@@ -64,14 +67,25 @@\n     if (!audioBlob) {\n         alert(\"Please record something first!\");\n         return;\n     }\n+\n     // Placeholder for sending the audioBlob to a voice-to-text service\n-    let transcribedText = \"This is a placeholder for the transcribed text.\"; // This should be replaced with actual transcribed text\n+    let transcribedText = \"This is a placeholder for the transcribed text.\"; \n+\n+    const sourceLang = 'en'; \n+    const languageSelect = document.getElementById(\"languageSelect\");\n+    const selectedLanguages = Array.from(languageSelect.selectedOptions).map(option => option.value);\n     \n-    const sourceLang = 'en'; // Assuming the source language is English\n-    const targetLang = document.getElementById(\"languageSelect\").value;\n-    \n-    await translateText(sourceLang, targetLang, transcribedText);\n+    const translatedContainer = document.getElementById(\"translatedTextContainer\");\n+    translatedContainer.innerHTML = \"\";  // Clear previous translations\n+\n+    for (let targetLang of selectedLanguages) {\n+        let translated = await translateText(sourceLang, targetLang, transcribedText);\n+        let translatedDiv = document.createElement(\"div\");\n+        translatedDiv.textContent = `Translation (${targetLang}): ${translated}`;\n+        translatedContainer.appendChild(translatedDiv);\n+    }\n }\n+\n // Populate the language dropdown on page load\n populateLanguageDropdown();\n"
                },
                {
                    "date": 1693387841270,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -71,17 +71,17 @@\n \n     // Placeholder for sending the audioBlob to a voice-to-text service\n     let transcribedText = \"This is a placeholder for the transcribed text.\"; \n \n-    const sourceLang = 'en'; \n+    const sourceLang = 'EN';  // DeepL uses uppercase language codes\n     const languageSelect = document.getElementById(\"languageSelect\");\n     const selectedLanguages = Array.from(languageSelect.selectedOptions).map(option => option.value);\n     \n     const translatedContainer = document.getElementById(\"translatedTextContainer\");\n     translatedContainer.innerHTML = \"\";  // Clear previous translations\n \n     for (let targetLang of selectedLanguages) {\n-        let translated = await translateText(sourceLang, targetLang, transcribedText);\n+        let translated = await translateWithDeepL(sourceLang, targetLang, transcribedText);\n         let translatedDiv = document.createElement(\"div\");\n         translatedDiv.textContent = `Translation (${targetLang}): ${translated}`;\n         translatedContainer.appendChild(translatedDiv);\n     }\n"
                },
                {
                    "date": 1693388096267,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -86,6 +86,7 @@\n         translatedContainer.appendChild(translatedDiv);\n     }\n }\n \n+\n // Populate the language dropdown on page load\n populateLanguageDropdown();\n"
                },
                {
                    "date": 1693389110814,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -86,7 +86,6 @@\n         translatedContainer.appendChild(translatedDiv);\n     }\n }\n \n-\n // Populate the language dropdown on page load\n populateLanguageDropdown();\n"
                },
                {
                    "date": 1693501967530,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -71,17 +71,17 @@\n \n     // Placeholder for sending the audioBlob to a voice-to-text service\n     let transcribedText = \"This is a placeholder for the transcribed text.\"; \n \n-    const sourceLang = 'EN';  // DeepL uses uppercase language codes\n+    const sourceLang = 'EN';  // Adjust as needed\n     const languageSelect = document.getElementById(\"languageSelect\");\n     const selectedLanguages = Array.from(languageSelect.selectedOptions).map(option => option.value);\n     \n     const translatedContainer = document.getElementById(\"translatedTextContainer\");\n     translatedContainer.innerHTML = \"\";  // Clear previous translations\n \n     for (let targetLang of selectedLanguages) {\n-        let translated = await translateWithDeepL(sourceLang, targetLang, transcribedText);\n+        let translated = await translateWithMyMemory(sourceLang, targetLang, transcribedText);\n         let translatedDiv = document.createElement(\"div\");\n         translatedDiv.textContent = `Translation (${targetLang}): ${translated}`;\n         translatedContainer.appendChild(translatedDiv);\n     }\n"
                },
                {
                    "date": 1693517473512,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -26,13 +26,14 @@\n         audio.src = audioUrl;\n         \n         const audioPlayer = document.getElementById(\"audioPlayer\");\n         audioPlayer.src = audioUrl;\n-        audioPlayer.style.display = \"block\";\n \n         const downloadLink = document.getElementById(\"downloadAudio\");\n         downloadLink.href = audioUrl;\n-        downloadLink.style.display = \"block\";\n+\n+        // Save the recording\n+        saveRecording(audioUrl);\n     };\n     mediaRecorder.start();\n     document.getElementById(\"startRecord\").disabled = true;\n     document.getElementById(\"stopRecord\").disabled = false;\n@@ -62,8 +63,21 @@\n     audioPlayer.currentTime = 0;\n     audioPlayer.play();\n }\n \n+function saveRecording(url) {\n+    const savedRecordings = document.getElementById(\"savedRecordings\");\n+    const recordingItem = document.createElement(\"div\");\n+    recordingItem.className = \"recording-item\";\n+    \n+    const audioPlayer = document.createElement(\"audio\");\n+    audioPlayer.controls = true;\n+    audioPlayer.src = url;\n+\n+    recordingItem.appendChild(audioPlayer);\n+    savedRecordings.appendChild(recordingItem);\n+}\n+\n async function translateRecording() {\n     if (!audioBlob) {\n         alert(\"Please record something first!\");\n         return;\n@@ -71,9 +85,9 @@\n \n     // Placeholder for sending the audioBlob to a voice-to-text service\n     let transcribedText = \"This is a placeholder for the transcribed text.\"; \n \n-    const sourceLang = 'EN';  // Adjust as needed\n+    const sourceLang = 'EN';  // DeepL uses uppercase language codes\n     const languageSelect = document.getElementById(\"languageSelect\");\n     const selectedLanguages = Array.from(languageSelect.selectedOptions).map(option => option.value);\n     \n     const translatedContainer = document.getElementById(\"translatedTextContainer\");\n"
                },
                {
                    "date": 1693517834064,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -58,13 +58,20 @@\n     document.getElementById(\"recordingStatus\").textContent = \"Recording Stopped\";\n }\n \n function playLastRecording() {\n+    if (!audioUrl) {\n+        alert(\"No recording available to play.\");\n+        return;\n+    }\n+\n     const audioPlayer = document.getElementById(\"audioPlayer\");\n+    audioPlayer.src = audioUrl;\n     audioPlayer.currentTime = 0;\n     audioPlayer.play();\n }\n \n+\n function saveRecording(url) {\n     const savedRecordings = document.getElementById(\"savedRecordings\");\n     const recordingItem = document.createElement(\"div\");\n     recordingItem.className = \"recording-item\";\n@@ -82,17 +89,21 @@\n         alert(\"Please record something first!\");\n         return;\n     }\n \n-    // Placeholder for sending the audioBlob to a voice-to-text service\n     let transcribedText = \"This is a placeholder for the transcribed text.\"; \n \n-    const sourceLang = 'EN';  // DeepL uses uppercase language codes\n+    const sourceLang = 'EN'; // Assuming English as the default source language\n     const languageSelect = document.getElementById(\"languageSelect\");\n     const selectedLanguages = Array.from(languageSelect.selectedOptions).map(option => option.value);\n-    \n+\n+    if (selectedLanguages.includes(sourceLang)) {\n+        alert(\"Please select a different language than the source language for translation.\");\n+        return;\n+    }\n+\n     const translatedContainer = document.getElementById(\"translatedTextContainer\");\n-    translatedContainer.innerHTML = \"\";  // Clear previous translations\n+    translatedContainer.innerHTML = \"\"; // Clear previous translations\n \n     for (let targetLang of selectedLanguages) {\n         let translated = await translateWithMyMemory(sourceLang, targetLang, transcribedText);\n         let translatedDiv = document.createElement(\"div\");\n@@ -100,6 +111,7 @@\n         translatedContainer.appendChild(translatedDiv);\n     }\n }\n \n+\n // Populate the language dropdown on page load\n populateLanguageDropdown();\n"
                },
                {
                    "date": 1693568584052,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,18 +22,16 @@\n     };\n     mediaRecorder.onstop = () => {\n         audioBlob = new Blob(audioChunks, { type: 'audio/wav' });\n         audioUrl = URL.createObjectURL(audioBlob);\n-        audio.src = audioUrl;\n         \n         const audioPlayer = document.getElementById(\"audioPlayer\");\n         audioPlayer.src = audioUrl;\n+        audioPlayer.style.display = \"block\";\n \n         const downloadLink = document.getElementById(\"downloadAudio\");\n         downloadLink.href = audioUrl;\n-\n-        // Save the recording\n-        saveRecording(audioUrl);\n+        downloadLink.style.display = \"block\";\n     };\n     mediaRecorder.start();\n     document.getElementById(\"startRecord\").disabled = true;\n     document.getElementById(\"stopRecord\").disabled = false;\n@@ -64,54 +62,36 @@\n         return;\n     }\n \n     const audioPlayer = document.getElementById(\"audioPlayer\");\n-    audioPlayer.src = audioUrl;\n     audioPlayer.currentTime = 0;\n     audioPlayer.play();\n }\n \n-\n-function saveRecording(url) {\n-    const savedRecordings = document.getElementById(\"savedRecordings\");\n-    const recordingItem = document.createElement(\"div\");\n-    recordingItem.className = \"recording-item\";\n-    \n-    const audioPlayer = document.createElement(\"audio\");\n-    audioPlayer.controls = true;\n-    audioPlayer.src = url;\n-\n-    recordingItem.appendChild(audioPlayer);\n-    savedRecordings.appendChild(recordingItem);\n-}\n-\n async function translateRecording() {\n     if (!audioBlob) {\n         alert(\"Please record something first!\");\n         return;\n     }\n \n+    // Placeholder for sending the audioBlob to a voice-to-text service\n     let transcribedText = \"This is a placeholder for the transcribed text.\"; \n \n-    const sourceLang = 'EN'; // Assuming English as the default source language\n+    const sourceLang = 'en'; \n     const languageSelect = document.getElementById(\"languageSelect\");\n     const selectedLanguages = Array.from(languageSelect.selectedOptions).map(option => option.value);\n-\n-    if (selectedLanguages.includes(sourceLang)) {\n-        alert(\"Please select a different language than the source language for translation.\");\n-        return;\n-    }\n-\n+    \n     const translatedContainer = document.getElementById(\"translatedTextContainer\");\n-    translatedContainer.innerHTML = \"\"; // Clear previous translations\n+    translatedContainer.innerHTML = \"\";  // Clear previous translations\n \n     for (let targetLang of selectedLanguages) {\n-        let translated = await translateWithMyMemory(sourceLang, targetLang, transcribedText);\n-        let translatedDiv = document.createElement(\"div\");\n-        translatedDiv.textContent = `Translation (${targetLang}): ${translated}`;\n-        translatedContainer.appendChild(translatedDiv);\n+        if (sourceLang !== targetLang) {\n+            let translated = await translateText(sourceLang, targetLang, transcribedText);\n+            let translatedDiv = document.createElement(\"div\");\n+            translatedDiv.textContent = `Translation (${targetLang}): ${translated}`;\n+            translatedContainer.appendChild(translatedDiv);\n+        }\n     }\n }\n \n-\n // Populate the language dropdown on page load\n populateLanguageDropdown();\n"
                },
                {
                    "date": 1693568703614,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,16 +22,18 @@\n     };\n     mediaRecorder.onstop = () => {\n         audioBlob = new Blob(audioChunks, { type: 'audio/wav' });\n         audioUrl = URL.createObjectURL(audioBlob);\n+        audio.src = audioUrl;\n         \n         const audioPlayer = document.getElementById(\"audioPlayer\");\n         audioPlayer.src = audioUrl;\n-        audioPlayer.style.display = \"block\";\n \n         const downloadLink = document.getElementById(\"downloadAudio\");\n         downloadLink.href = audioUrl;\n-        downloadLink.style.display = \"block\";\n+\n+        // Save the recording\n+        saveRecording(audioUrl);\n     };\n     mediaRecorder.start();\n     document.getElementById(\"startRecord\").disabled = true;\n     document.getElementById(\"stopRecord\").disabled = false;\n@@ -62,36 +64,54 @@\n         return;\n     }\n \n     const audioPlayer = document.getElementById(\"audioPlayer\");\n+    audioPlayer.src = audioUrl;\n     audioPlayer.currentTime = 0;\n     audioPlayer.play();\n }\n \n+\n+function saveRecording(url) {\n+    const savedRecordings = document.getElementById(\"savedRecordings\");\n+    const recordingItem = document.createElement(\"div\");\n+    recordingItem.className = \"recording-item\";\n+    \n+    const audioPlayer = document.createElement(\"audio\");\n+    audioPlayer.controls = true;\n+    audioPlayer.src = url;\n+\n+    recordingItem.appendChild(audioPlayer);\n+    savedRecordings.appendChild(recordingItem);\n+}\n+\n async function translateRecording() {\n     if (!audioBlob) {\n         alert(\"Please record something first!\");\n         return;\n     }\n \n-    // Placeholder for sending the audioBlob to a voice-to-text service\n     let transcribedText = \"This is a placeholder for the transcribed text.\"; \n \n-    const sourceLang = 'en'; \n+    const sourceLang = 'EN'; // Assuming English as the default source language\n     const languageSelect = document.getElementById(\"languageSelect\");\n     const selectedLanguages = Array.from(languageSelect.selectedOptions).map(option => option.value);\n-    \n+\n+    if (selectedLanguages.includes(sourceLang)) {\n+        alert(\"Please select a different language than the source language for translation.\");\n+        return;\n+    }\n+\n     const translatedContainer = document.getElementById(\"translatedTextContainer\");\n-    translatedContainer.innerHTML = \"\";  // Clear previous translations\n+    translatedContainer.innerHTML = \"\"; // Clear previous translations\n \n     for (let targetLang of selectedLanguages) {\n-        if (sourceLang !== targetLang) {\n-            let translated = await translateText(sourceLang, targetLang, transcribedText);\n-            let translatedDiv = document.createElement(\"div\");\n-            translatedDiv.textContent = `Translation (${targetLang}): ${translated}`;\n-            translatedContainer.appendChild(translatedDiv);\n-        }\n+        let translated = await translateWithMyMemory(sourceLang, targetLang, transcribedText);\n+        let translatedDiv = document.createElement(\"div\");\n+        translatedDiv.textContent = `Translation (${targetLang}): ${translated}`;\n+        translatedContainer.appendChild(translatedDiv);\n     }\n }\n \n+\n // Populate the language dropdown on page load\n populateLanguageDropdown();\n"
                },
                {
                    "date": 1693572001260,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,11 +10,11 @@\n document.getElementById(\"playAudio\").addEventListener(\"click\", playLastRecording);\n document.getElementById(\"translate\").addEventListener(\"click\", translateRecording);\n \n async function startRecording() {\n-    audioChunks = []; // Clear previous recording chunks\n-    audioBlob = null; // Reset previous audio blob\n-    audioUrl = null; // Reset previous audio URL\n+    audioChunks = [];\n+    audioBlob = null;\n+    audioUrl = null;\n \n     let stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n     mediaRecorder = new MediaRecorder(stream);\n     mediaRecorder.ondataavailable = event => {\n@@ -26,92 +26,55 @@\n         audio.src = audioUrl;\n         \n         const audioPlayer = document.getElementById(\"audioPlayer\");\n         audioPlayer.src = audioUrl;\n-\n-        const downloadLink = document.getElementById(\"downloadAudio\");\n-        downloadLink.href = audioUrl;\n-\n-        // Save the recording\n-        saveRecording(audioUrl);\n+        audioPlayer.style.display = \"block\";\n     };\n     mediaRecorder.start();\n+\n+    // Update UI for recording\n     document.getElementById(\"startRecord\").disabled = true;\n     document.getElementById(\"stopRecord\").disabled = false;\n-\n-    let recordingDuration = 0;\n-    document.getElementById(\"recordingStatus\").textContent = \"Recording: 00:00\";\n-    recordingInterval = setInterval(() => {\n-        recordingDuration += 1;\n-        let minutes = Math.floor(recordingDuration / 60);\n-        let seconds = recordingDuration % 60;\n-        document.getElementById(\"recordingStatus\").textContent = `Recording: ${String(minutes).padStart(2, '0')}:${String(seconds).padStart(2, '0')}`;\n-    }, 1000);\n }\n \n function stopRecording() {\n-    mediaRecorder.stop();\n+    if (mediaRecorder) {\n+        mediaRecorder.stop();\n+    }\n+\n+    // Update UI after recording\n     document.getElementById(\"startRecord\").disabled = false;\n     document.getElementById(\"stopRecord\").disabled = true;\n-    document.getElementById(\"playAudio\").disabled = false;\n-\n-    clearInterval(recordingInterval);\n-    document.getElementById(\"recordingStatus\").textContent = \"Recording Stopped\";\n }\n \n function playLastRecording() {\n-    if (!audioUrl) {\n-        alert(\"No recording available to play.\");\n-        return;\n+    if (audioUrl) {\n+        audio.play();\n+    } else {\n+        alert(\"No recording available. Please record something first.\");\n     }\n-\n-    const audioPlayer = document.getElementById(\"audioPlayer\");\n-    audioPlayer.src = audioUrl;\n-    audioPlayer.currentTime = 0;\n-    audioPlayer.play();\n }\n \n-\n-function saveRecording(url) {\n-    const savedRecordings = document.getElementById(\"savedRecordings\");\n-    const recordingItem = document.createElement(\"div\");\n-    recordingItem.className = \"recording-item\";\n-    \n-    const audioPlayer = document.createElement(\"audio\");\n-    audioPlayer.controls = true;\n-    audioPlayer.src = url;\n-\n-    recordingItem.appendChild(audioPlayer);\n-    savedRecordings.appendChild(recordingItem);\n-}\n-\n async function translateRecording() {\n     if (!audioBlob) {\n         alert(\"Please record something first!\");\n         return;\n     }\n \n+    // Placeholder for sending the audioBlob to a voice-to-text service\n     let transcribedText = \"This is a placeholder for the transcribed text.\"; \n \n-    const sourceLang = 'EN'; // Assuming English as the default source language\n+    const sourceLang = 'en';\n     const languageSelect = document.getElementById(\"languageSelect\");\n-    const selectedLanguages = Array.from(languageSelect.selectedOptions).map(option => option.value);\n-\n-    if (selectedLanguages.includes(sourceLang)) {\n-        alert(\"Please select a different language than the source language for translation.\");\n-        return;\n-    }\n-\n+    const targetLang = languageSelect.value;\n+    \n     const translatedContainer = document.getElementById(\"translatedTextContainer\");\n-    translatedContainer.innerHTML = \"\"; // Clear previous translations\n+    translatedContainer.innerHTML = \"\";  // Clear previous translations\n \n-    for (let targetLang of selectedLanguages) {\n-        let translated = await translateWithMyMemory(sourceLang, targetLang, transcribedText);\n-        let translatedDiv = document.createElement(\"div\");\n-        translatedDiv.textContent = `Translation (${targetLang}): ${translated}`;\n-        translatedContainer.appendChild(translatedDiv);\n-    }\n+    let translated = await translateText(transcribedText, sourceLang, targetLang);\n+    let translatedDiv = document.createElement(\"div\");\n+    translatedDiv.textContent = `Translation (${targetLang}): ${translated}`;\n+    translatedContainer.appendChild(translatedDiv);\n }\n \n-\n // Populate the language dropdown on page load\n populateLanguageDropdown();\n"
                },
                {
                    "date": 1693572074658,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -30,21 +30,32 @@\n         audioPlayer.style.display = \"block\";\n     };\n     mediaRecorder.start();\n \n-    // Update UI for recording\n+    // UI updates for recording\n     document.getElementById(\"startRecord\").disabled = true;\n     document.getElementById(\"stopRecord\").disabled = false;\n+\n+    let recordingDuration = 0;\n+    document.getElementById(\"recordingStatus\").textContent = \"Recording: 00:00\";\n+    recordingInterval = setInterval(() => {\n+        recordingDuration += 1;\n+        let minutes = Math.floor(recordingDuration / 60);\n+        let seconds = recordingDuration % 60;\n+        document.getElementById(\"recordingStatus\").textContent = `Recording: ${String(minutes).padStart(2, '0')}:${String(seconds).padStart(2, '0')}`;\n+    }, 1000);\n }\n \n function stopRecording() {\n     if (mediaRecorder) {\n         mediaRecorder.stop();\n     }\n \n-    // Update UI after recording\n+    // UI updates after recording\n     document.getElementById(\"startRecord\").disabled = false;\n     document.getElementById(\"stopRecord\").disabled = true;\n+    clearInterval(recordingInterval);\n+    document.getElementById(\"recordingStatus\").textContent = \"Recording Stopped\";\n }\n \n function playLastRecording() {\n     if (audioUrl) {\n"
                },
                {
                    "date": 1693572547931,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,11 +10,11 @@\n document.getElementById(\"playAudio\").addEventListener(\"click\", playLastRecording);\n document.getElementById(\"translate\").addEventListener(\"click\", translateRecording);\n \n async function startRecording() {\n-    audioChunks = [];\n-    audioBlob = null;\n-    audioUrl = null;\n+    audioChunks = []; // Clear previous recording chunks\n+    audioBlob = null; // Reset previous audio blob\n+    audioUrl = null; // Reset previous audio URL\n \n     let stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n     mediaRecorder = new MediaRecorder(stream);\n     mediaRecorder.ondataavailable = event => {\n@@ -27,12 +27,15 @@\n         \n         const audioPlayer = document.getElementById(\"audioPlayer\");\n         audioPlayer.src = audioUrl;\n         audioPlayer.style.display = \"block\";\n+        \n+        const downloadLink = document.getElementById(\"downloadAudio\");\n+        downloadLink.href = audioUrl;\n+        downloadLink.style.display = \"block\";\n     };\n     mediaRecorder.start();\n \n-    // UI updates for recording\n     document.getElementById(\"startRecord\").disabled = true;\n     document.getElementById(\"stopRecord\").disabled = false;\n \n     let recordingDuration = 0;\n@@ -45,25 +48,26 @@\n     }, 1000);\n }\n \n function stopRecording() {\n-    if (mediaRecorder) {\n-        mediaRecorder.stop();\n-    }\n-\n-    // UI updates after recording\n+    mediaRecorder.stop();\n     document.getElementById(\"startRecord\").disabled = false;\n     document.getElementById(\"stopRecord\").disabled = true;\n+    document.getElementById(\"playAudio\").disabled = false;\n+\n     clearInterval(recordingInterval);\n     document.getElementById(\"recordingStatus\").textContent = \"Recording Stopped\";\n }\n \n function playLastRecording() {\n-    if (audioUrl) {\n-        audio.play();\n-    } else {\n-        alert(\"No recording available. Please record something first.\");\n+    if (!audioUrl) {\n+        alert(\"No recording available to play.\");\n+        return;\n     }\n+\n+    const audioPlayer = document.getElementById(\"audioPlayer\");\n+    audioPlayer.currentTime = 0;\n+    audioPlayer.play();\n }\n \n async function translateRecording() {\n     if (!audioBlob) {\n@@ -73,19 +77,41 @@\n \n     // Placeholder for sending the audioBlob to a voice-to-text service\n     let transcribedText = \"This is a placeholder for the transcribed text.\"; \n \n-    const sourceLang = 'en';\n+    const sourceLang = 'en'; \n     const languageSelect = document.getElementById(\"languageSelect\");\n-    const targetLang = languageSelect.value;\n+    const selectedLanguages = Array.from(languageSelect.selectedOptions).map(option => option.value);\n     \n     const translatedContainer = document.getElementById(\"translatedTextContainer\");\n     translatedContainer.innerHTML = \"\";  // Clear previous translations\n \n-    let translated = await translateText(transcribedText, sourceLang, targetLang);\n-    let translatedDiv = document.createElement(\"div\");\n-    translatedDiv.textContent = `Translation (${targetLang}): ${translated}`;\n-    translatedContainer.appendChild(translatedDiv);\n+    for (let targetLang of selectedLanguages) {\n+        if (sourceLang !== targetLang) {\n+            let translated = await translateText(transcribedText, sourceLang, targetLang);\n+            let translatedDiv = document.createElement(\"div\");\n+            translatedDiv.textContent = `Translation (${targetLang}): ${translated}`;\n+            translatedContainer.appendChild(translatedDiv);\n+        }\n+    }\n }\n \n+async function translateText(text, sourceLang, targetLang) {\n+    const API_ENDPOINT = `https://api.mymemory.translated.net/get?q=${text}&langpair=${sourceLang}|${targetLang}`;\n+    \n+    try {\n+        const response = await fetch(API_ENDPOINT);\n+        const data = await response.json();\n+\n+        if (data.responseStatus === 200) {\n+            return data.responseData.translatedText;\n+        } else {\n+            throw new Error(data.responseDetails || \"Translation failed\");\n+        }\n+    } catch (error) {\n+        console.error(\"Error translating text:\", error);\n+        return \"Translation error. Please try again.\";\n+    }\n+}\n+\n // Populate the language dropdown on page load\n populateLanguageDropdown();\n"
                },
                {
                    "date": 1693583307133,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,19 +23,18 @@\n     mediaRecorder.onstop = () => {\n         audioBlob = new Blob(audioChunks, { type: 'audio/wav' });\n         audioUrl = URL.createObjectURL(audioBlob);\n         audio.src = audioUrl;\n-        \n+\n         const audioPlayer = document.getElementById(\"audioPlayer\");\n         audioPlayer.src = audioUrl;\n         audioPlayer.style.display = \"block\";\n-        \n+\n         const downloadLink = document.getElementById(\"downloadAudio\");\n         downloadLink.href = audioUrl;\n         downloadLink.style.display = \"block\";\n     };\n     mediaRecorder.start();\n-\n     document.getElementById(\"startRecord\").disabled = true;\n     document.getElementById(\"stopRecord\").disabled = false;\n \n     let recordingDuration = 0;\n@@ -58,60 +57,44 @@\n     document.getElementById(\"recordingStatus\").textContent = \"Recording Stopped\";\n }\n \n function playLastRecording() {\n-    if (!audioUrl) {\n+    const audioPlayer = document.getElementById(\"audioPlayer\");\n+    if (audioPlayer) {\n+        audioPlayer.currentTime = 0;\n+        audioPlayer.play();\n+    } else {\n         alert(\"No recording available to play.\");\n-        return;\n     }\n-\n-    const audioPlayer = document.getElementById(\"audioPlayer\");\n-    audioPlayer.currentTime = 0;\n-    audioPlayer.play();\n }\n \n async function translateRecording() {\n-    if (!audioBlob) {\n-        alert(\"Please record something first!\");\n+    let textToTranslate = document.getElementById(\"inputText\").value;\n+    if (!textToTranslate && !audioBlob) {\n+        alert(\"Please record something or input text to translate!\");\n         return;\n     }\n \n-    // Placeholder for sending the audioBlob to a voice-to-text service\n-    let transcribedText = \"This is a placeholder for the transcribed text.\"; \n+    if (!textToTranslate) {\n+        // Placeholder for sending the audioBlob to a voice-to-text service\n+        textToTranslate = \"This is a placeholder for the transcribed text.\";\n+    }\n \n-    const sourceLang = 'en'; \n+    const sourceLang = 'en';\n     const languageSelect = document.getElementById(\"languageSelect\");\n     const selectedLanguages = Array.from(languageSelect.selectedOptions).map(option => option.value);\n-    \n+\n     const translatedContainer = document.getElementById(\"translatedTextContainer\");\n     translatedContainer.innerHTML = \"\";  // Clear previous translations\n \n     for (let targetLang of selectedLanguages) {\n         if (sourceLang !== targetLang) {\n-            let translated = await translateText(transcribedText, sourceLang, targetLang);\n+            let translated = await translateText(sourceLang, targetLang, textToTranslate);\n             let translatedDiv = document.createElement(\"div\");\n             translatedDiv.textContent = `Translation (${targetLang}): ${translated}`;\n             translatedContainer.appendChild(translatedDiv);\n         }\n     }\n }\n \n-async function translateText(text, sourceLang, targetLang) {\n-    const API_ENDPOINT = `https://api.mymemory.translated.net/get?q=${text}&langpair=${sourceLang}|${targetLang}`;\n-    \n-    try {\n-        const response = await fetch(API_ENDPOINT);\n-        const data = await response.json();\n-\n-        if (data.responseStatus === 200) {\n-            return data.responseData.translatedText;\n-        } else {\n-            throw new Error(data.responseDetails || \"Translation failed\");\n-        }\n-    } catch (error) {\n-        console.error(\"Error translating text:\", error);\n-        return \"Translation error. Please try again.\";\n-    }\n-}\n-\n // Populate the language dropdown on page load\n populateLanguageDropdown();\n"
                }
            ],
            "date": 1693164066955,
            "name": "Commit-0",
            "content": "let mediaRecorder;\nlet recordedChunks = [];\n\ndocument.getElementById('startRecord').onclick = function() {\n    navigator.mediaDevices.getUserMedia({ audio: true })\n        .then(stream => {\n            mediaRecorder = new MediaRecorder(stream);\n            mediaRecorder.ondataavailable = function(event) {\n                if (event.data.size > 0) {\n                    recordedChunks.push(event.data);\n                }\n            };\n            \n            mediaRecorder.onstop = function() {\n                let blob = new Blob(recordedChunks, { type: 'audio/wav' });\n                let url = URL.createObjectURL(blob);\n                let li = document.createElement('li');\n                let audio = new Audio(url);\n                audio.controls = true;\n                li.appendChild(audio);\n                document.getElementById('recordingsList').appendChild(li);\n                document.getElementById('playAudio').disabled = false;\n                recordedChunks = [];\n            };\n\n            mediaRecorder.start();\n            document.getElementById('startRecord').disabled = true;\n            document.getElementById('stopRecord').disabled = false;\n        });\n};\n\ndocument.getElementById('stopRecord').onclick = function() {\n    mediaRecorder.stop();\n    document.getElementById('startRecord').disabled = false;\n    document.getElementById('stopRecord').disabled = true;\n};\n\ndocument.getElementById('playAudio').onclick = function() {\n    let lastRecording = document.getElementById('recordingsList').lastChild.firstChild;\n    lastRecording.play();\n};\n"
        }
    ]
}